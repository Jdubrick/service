# Minimal service configuration
---
llm_providers:
  - name: my_openai
    type: openai
    url: "https://api.openai.com/v1"
    credentials_path: openai_api_key.txt
    models:
      - name: gpt-3.5-turbo
ols_config:
  conversation_cache:
    type: memory
    memory:
      max_entries: 1000
  default_provider: my_openai
  default_model: gpt-3.5-turbo
  authentication_config:
    module: "noop"

dev_config:
  # config options specific to dev environment - launching OLS in local
  enable_dev_ui: true
  disable_auth: true
  disable_tls: true

